# Multilingual-SocialRobot-Education

## Project Overview
This project focuses on the development of Android-based applications for the Buddy social robot to enhance *multicultural inclusivity* in early childhood education. The applications implement *multilingual engagement*, *cultural exploration*, and *social inclusion* scenarios, utilizing advanced *speech recognition*, *gesture simulation*, and *adaptive learning* technologies.

---

## Scenario 1: Multilingual Engagement


### Description
In the *Multilingual Engagement* scenario, the Buddy robot is designed to interact with children in multiple languages, ensuring every child feels included and supported in a diverse classroom environment. By leveraging real-time speech recognition and synthesis technologies, Buddy can identify the language spoken by the child and respond appropriately, fostering an inclusive and engaging atmosphere for learning.

### Technical Details
- *Speech Recognition and Synthesis*:
  - Uses *Microsoft Azure Cognitive Services* to process spoken inputs, convert them into text (Speech-to-Text), and generate responses (Text-to-Speech).
  - Supports multiple languages, ensuring adaptability to diverse classroom settings.
  - Configured for dynamic language switching based on the detected input.
- *Gesture Simulation*:
  - Buddy uses its screen to simulate social gestures such as waving, nodding, or smiling.
  - Pre-rendered animations are displayed using the *Glide library* for smooth multimedia integration.
- *Interactive Features*:
  - Buddy greets children in their native language.
  - Displays visual cues like waving hands or smiling faces to enhance interaction.

### Educational Impact
This scenario helps children build confidence in their native languages while fostering inclusivity. It supports linguistic development and allows children to experience the joy of being understood in their preferred language.
